<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover">
    <title>OMEGA: OMNI-SIGHT (MULTI-AI)</title>
    
    <!-- CORE AI ENGINE (TENSORFLOW) -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0"></script>
    
    <!-- 1. OBJECT DETECTION MODEL -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd@2.2.2"></script>
    
    <!-- 2. POSE DETECTION MODEL -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection@0.0.6"></script>
    
    <!-- 3. FACE MESH MODEL -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection@0.0.3"></script>

    <style>
        :root {
            --p: #00ff9d; /* Primary */
            --s: #00a8ff; /* Skeleton */
            --f: #ff00ff; /* Face */
            --bg: #000;
            --font: 'Segoe UI', monospace;
        }
        
        body { margin: 0; overflow: hidden; background: var(--bg); color: var(--p); font-family: var(--font); }
        
        #viewport { position: relative; width: 100vw; height: 100vh; }
        #camera-feed { position: absolute; inset: 0; width: 100%; height: 100%; object-fit: cover; z-index: 0; opacity: 0.8; filter: contrast(1.2) brightness(0.8); }
        #hud-canvas { position: absolute; inset: 0; z-index: 10; }

        /* UI PANELS */
        #ui-layer { position: absolute; inset: 0; z-index: 20; padding: 10px; pointer-events: none; display: flex; flex-direction: column; justify-content: space-between; }
        
        .panel {
            background: rgba(0, 10, 5, 0.85); border-left: 3px solid var(--p);
            padding: 8px 12px; margin-bottom: 5px; backdrop-filter: blur(5px);
            pointer-events: auto; width: fit-content; border-radius: 0 5px 5px 0;
            box-shadow: 0 0 10px rgba(0,255,157,0.1);
        }
        .label { font-size: 9px; color: #888; font-weight: 900; letter-spacing: 1px; }
        .val { font-size: 12px; color: #fff; font-weight: bold; font-family: monospace; }
        
        .led { display: inline-block; width: 8px; height: 8px; border-radius: 50%; background: #333; margin-right: 5px; }
        .led.on { background: var(--p); box-shadow: 0 0 8px var(--p); }
        .led.busy { background: #ffae00; animation: pulse 0.5s infinite; }

        /* BOOT SCREEN */
        #boot { position: fixed; inset: 0; background: #000; z-index: 9999; display: flex; flex-direction: column; align-items: center; justify-content: center; }
        .loader-ring { width: 60px; height: 60px; border: 4px solid #111; border-top: 4px solid var(--p); border-radius: 50%; animation: spin 1s infinite; margin-bottom: 20px; }
        @keyframes spin { to { transform: rotate(360deg); } }
        @keyframes pulse { 50% { opacity: 0.5; } }
        
        button { background: transparent; border: 1px solid var(--p); color: var(--p); padding: 10px 30px; font-weight: bold; cursor: pointer; clip-path: polygon(10% 0, 100% 0, 100% 70%, 90% 100%, 0 100%, 0 30%); }
        button:hover { background: var(--p); color: #000; }
    </style>
</head>
<body>

    <div id="viewport">
        <video id="camera-feed" autoplay playsinline muted></video>
        <canvas id="hud-canvas"></canvas>

        <div id="ui-layer">
            <!-- TOP LEFT: AI STATUS -->
            <div>
                <div class="panel">
                    <div class="label">NEURAL NETWORKS</div>
                    <div><span id="led-obj" class="led"></span> OBJECT DETECT</div>
                    <div><span id="led-pose" class="led"></span> SKELETON TRACK</div>
                    <div><span id="led-face" class="led"></span> FACE MESH</div>
                </div>
                <div class="panel">
                    <div class="label">PERFORMANCE</div>
                    <div>FPS: <span id="fps" class="val">0</span></div>
                    <div>LATENCY: <span id="ms" class="val">0ms</span></div>
                </div>
            </div>

            <!-- BOTTOM: DATA -->
            <div>
                <div class="panel">
                    <div class="label">ANALYSIS</div>
                    <div>HUMANS: <span id="human-count" class="val">0</span></div>
                    <div>POSTURE: <span id="posture-status" class="val" style="color:var(--s)">SCANNING</span></div>
                </div>
            </div>
        </div>
    </div>

    <div id="boot">
        <h1 style="color:var(--p); letter-spacing: 5px;">OMEGA: OMNI-SIGHT</h1>
        <div class="loader-ring"></div>
        <div id="boot-log" style="color:#666; font-size:10px; margin-bottom:20px;">INITIALIZING...</div>
        <button id="btn-start" onclick="OMEGA.start()" style="display:none;">ACTIVATE ALL SYSTEMS</button>
    </div>

<script>
/**
 * OMEGA: OMNI-SIGHT EDITION
 * Multi-Model AI Fusion (Object + Pose + Face)
 */

const CONFIG = {
    OBJ_CONF: 0.5,
    POSE_CONF: 0.4,
    MAX_FACES: 3
};

// --- AI KERNEL (The Brain) ---
class MultiAIKernel {
    constructor() {
        this.netObject = null;
        this.netPose = null;
        this.netFace = null;
        this.status = { obj: false, pose: false, face: false };
    }

    async loadAll(onProgress) {
        try {
            // 1. Load Object Detection
            onProgress("Loading Cortex 1: Objects...");
            this.netObject = await cocoSsd.load({base: 'lite_mobilenet_v2'});
            this.status.obj = true;

            // 2. Load Pose Detection (MoveNet Lightning - Fast)
            onProgress("Loading Cortex 2: Skeleton...");
            this.netPose = await poseDetection.createDetector(
                poseDetection.SupportedModels.MoveNet,
                { modelType: poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING }
            );
            this.status.pose = true;

            // 3. Load Face Mesh
            onProgress("Loading Cortex 3: Biometrics...");
            this.netFace = await faceLandmarksDetection.load(
                faceLandmarksDetection.SupportedPackages.mediapipeFacemesh
            );
            this.status.face = true;

            return true;
        } catch (e) {
            console.error(e);
            onProgress("Error: " + e.message);
            return false;
        }
    }

    async analyze(video) {
        // Run inference in parallel? No, JS is single threaded.
        // Run sequentially but fast.
        
        const results = { objects: [], poses: [], faces: [] };

        if(this.status.obj) results.objects = await this.netObject.detect(video, 10, CONFIG.OBJ_CONF);
        
        // Only run heavy pose/face if humans are detected to save battery
        const hasHuman = results.objects.some(o => o.class === 'person');
        
        if(this.status.pose && hasHuman) {
            const poses = await this.netPose.estimatePoses(video);
            results.poses = poses;
        }

        if(this.status.face && hasHuman) {
            const faces = await this.netFace.estimateFaces({input: video});
            results.faces = faces;
        }

        return results;
    }
}

// --- RENDERER (The Visuals) ---
class OmniRenderer {
    constructor() {
        this.canvas = document.getElementById('hud-canvas');
        this.ctx = this.canvas.getContext('2d');
        this.resize();
    }

    resize() {
        this.canvas.width = window.innerWidth;
        this.canvas.height = window.innerHeight;
    }

    render(video, data) {
        this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);
        const sx = this.canvas.width / video.videoWidth;
        const sy = this.canvas.height / video.videoHeight;

        // 1. RENDER FACES (The Deepest Layer)
        if(data.faces) {
            this.ctx.fillStyle = 'rgba(255, 0, 255, 0.6)'; // Magenta for Face
            data.faces.forEach(face => {
                face.scaledMesh.forEach((pt, i) => {
                    // Draw only some points to save FPS
                    if(i % 4 === 0) {
                        const x = pt[0] * sx; // Note: FaceMesh coords might need flip based on model
                        const y = pt[1] * sy;
                        this.ctx.fillRect(x, y, 2, 2);
                    }
                });
            });
        }

        // 2. RENDER POSE (Skeleton)
        if(data.poses && data.poses.length > 0) {
            const pose = data.poses[0]; // MoveNet SinglePose
            this.drawSkeleton(pose.keypoints, sx, sy);
        }

        // 3. RENDER OBJECTS (Boxes)
        data.objects.forEach(obj => {
            const [x,y,w,h] = obj.bbox;
            const scrX = x * sx; const scrY = y * sy;
            const scrW = w * sx; const scrH = h * sy;
            
            const color = obj.class === 'person' ? '#00ff9d' : '#ffae00';
            
            // Box
            this.ctx.strokeStyle = color;
            this.ctx.lineWidth = 2;
            this.ctx.strokeRect(scrX, scrY, scrW, scrH);
            
            // Text
            this.ctx.fillStyle = color;
            this.ctx.font = "bold 10px monospace";
            this.ctx.fillText(`${obj.class.toUpperCase()} ${Math.round(obj.score*100)}%`, scrX, scrY - 5);
        });
    }

    drawSkeleton(keypoints, sx, sy) {
        const ctx = this.ctx;
        const connect = (a, b, color) => {
            const p1 = keypoints.find(k => k.name === a);
            const p2 = keypoints.find(k => k.name === b);
            if(p1 && p2 && p1.score > 0.3 && p2.score > 0.3) {
                ctx.beginPath();
                ctx.moveTo(p1.x * sx, p1.y * sy);
                ctx.lineTo(p2.x * sx, p2.y * sy);
                ctx.strokeStyle = color;
                ctx.lineWidth = 3;
                ctx.stroke();
            }
        };

        // Draw Bones (Cyan)
        const c = '#00a8ff';
        connect('left_shoulder', 'right_shoulder', c);
        connect('left_shoulder', 'left_elbow', c);
        connect('left_elbow', 'left_wrist', c);
        connect('right_shoulder', 'right_elbow', c);
        connect('right_elbow', 'right_wrist', c);
        connect('left_shoulder', 'left_hip', c);
        connect('right_shoulder', 'right_hip', c);
        connect('left_hip', 'right_hip', c);
        
        // Joints (Yellow)
        ctx.fillStyle = '#ffae00';
        keypoints.forEach(kp => {
            if(kp.score > 0.3) {
                ctx.beginPath();
                ctx.arc(kp.x * sx, kp.y * sy, 4, 0, 2*Math.PI);
                ctx.fill();
            }
        });
    }
}

// --- MAIN SYSTEM ---
class OmegaSystem {
    constructor() {
        this.video = document.getElementById('camera-feed');
        this.kernel = new MultiAIKernel();
        this.renderer = new OmniRenderer();
        this.isRunning = false;
        window.onresize = () => this.renderer.resize();
    }

    async init() {
        const log = document.getElementById('boot-log');
        const btn = document.getElementById('btn-start');
        
        const success = await this.kernel.loadAll((msg) => log.innerText = msg);
        
        if(success) {
            log.innerText = "SYSTEM OPTIMAL. STANDBY.";
            btn.style.display = 'block';
            // Setup LEDs
            document.getElementById('led-obj').classList.add('on');
            document.getElementById('led-pose').classList.add('on');
            document.getElementById('led-face').classList.add('on');
        } else {
            log.style.color = "red";
        }
    }

    async start() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({
                video: { facingMode: 'environment', width: {ideal: 640}, height: {ideal: 480} }, // Lower res for performance
                audio: false
            });
            this.video.srcObject = stream;
            await new Promise(r => this.video.onloadedmetadata = () => { this.video.play(); r(); });

            document.getElementById('boot').style.display = 'none';
            this.isRunning = true;
            this.loop();
        } catch(e) { alert("Camera Error: " + e.message); }
    }

    async loop() {
        if(!this.isRunning) return;
        const start = performance.now();

        // AI Analysis
        const data = await this.kernel.analyze(this.video);
        
        // Render
        this.renderer.render(this.video, data);

        // Logic & Stats
        const humans = data.objects.filter(o => o.class === 'person').length;
        document.getElementById('human-count').innerText = humans;
        
        // Analyze Posture Logic (Simple)
        const statusEl = document.getElementById('posture-status');
        if(data.poses.length > 0) {
            const p = data.poses[0].keypoints;
            const nose = p.find(k=>k.name==='nose');
            const lWrist = p.find(k=>k.name==='left_wrist');
            const rWrist = p.find(k=>k.name==='right_wrist');
            
            if(lWrist && rWrist && nose && (lWrist.y < nose.y || rWrist.y < nose.y)) {
                statusEl.innerText = "HANDS RAISED (ALERT)";
                statusEl.style.color = "#ff2a6d";
            } else {
                statusEl.innerText = "NEUTRAL";
                statusEl.style.color = "#00ff9d";
            }
        } else {
            statusEl.innerText = "NO TARGET";
            statusEl.style.color = "#888";
        }

        const ms = Math.round(performance.now() - start);
        document.getElementById('ms').innerText = ms + "ms";
        document.getElementById('fps').innerText = Math.round(1000/Math.max(1,ms));

        requestAnimationFrame(() => this.loop());
    }
}

const OMEGA = new OmegaSystem();
OMEGA.init();

</script>
</body>
</html>
