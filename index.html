<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>MOCHI: AI VISION</title>
    
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <link href="https://fonts.googleapis.com/css2?family=Fredoka+One&family=Nunito:wght@700&display=swap" rel="stylesheet">

    <style>
        body { margin: 0; overflow: hidden; background: #000; font-family: 'Nunito', sans-serif; }

        #camera {
            position: absolute; top: 0; left: 0; width: 100%; height: 100%;
            object-fit: cover; opacity: 0.8;
        }

        #ar-canvas {
            position: absolute; top: 0; left: 0; width: 100%; height: 100%;
            z-index: 2;
        }

        /* HUD */
        #ui-layer {
            position: absolute; top: 0; left: 0; width: 100%; height: 100%;
            z-index: 10; pointer-events: none; padding: 20px;
            display: flex; flex-direction: column; justify-content: space-between;
        }

        .status-pill {
            background: rgba(0,0,0,0.6); border: 1px solid #00ffcc;
            color: #00ffcc; padding: 8px 15px; border-radius: 20px;
            font-size: 12px; text-shadow: 0 0 5px #00ffcc;
            display: inline-block; backdrop-filter: blur(5px);
        }

        /* AI LOADING SCREEN */
        #loader {
            position: absolute; top: 0; left: 0; width: 100%; height: 100%;
            background: #000; z-index: 100;
            display: flex; flex-direction: column; align-items: center; justify-content: center;
            color: #00f3ff; font-family: 'Fredoka One';
        }
        .spinner {
            width: 50px; height: 50px; border: 5px solid #333;
            border-top: 5px solid #00f3ff; border-radius: 50%;
            animation: spin 1s linear infinite; margin-bottom: 20px;
        }
        @keyframes spin { 100% { transform: rotate(360deg); } }

        /* START BTN */
        #btn-start {
            display: none;
            padding: 15px 40px; font-size: 20px; background: #00f3ff; border: none;
            border-radius: 50px; font-weight: bold; cursor: pointer;
            box-shadow: 0 0 20px rgba(0, 243, 255, 0.5);
        }
    </style>
</head>
<body>

    <video id="camera" autoplay playsinline muted></video>
    <canvas id="ar-canvas"></canvas>

    <div id="ui-layer">
        <div>
            <div class="status-pill">AI VISION: <span id="ai-stat">OFFLINE</span></div>
            <div class="status-pill" style="margin-top:5px; border-color:#ff9a9e; color:#ff9a9e;">
                TARGET: <span id="target-name">NONE</span>
            </div>
        </div>
    </div>

    <div id="loader">
        <div class="spinner"></div>
        <div id="load-text">DOWNLOADING NEURAL NET...</div>
        <button id="btn-start">ACTIVATE VISION</button>
    </div>

<script>
/**
 * PROJECT: MOCHI VISION PRO
 * Integrates TensorFlow.js COCO-SSD model for Real-Time Object Detection
 */

const SYS = {
    width: window.innerWidth,
    height: window.innerHeight,
    ctx: null,
    canvas: document.getElementById('ar-canvas'),
    video: document.getElementById('camera'),
    model: null,
    predictions: [],
    isDetecting: false
};

// --- 1. AI BRAIN (TENSORFLOW) ---
const AI = {
    async init() {
        document.getElementById('load-text').innerText = "LOADING MODEL (10MB)...";
        // Load COCO-SSD Model
        SYS.model = await cocoSsd.load();
        
        document.getElementById('load-text').style.display = 'none';
        document.getElementById('btn-start').style.display = 'block';
        document.querySelector('.spinner').style.display = 'none';
    },

    async detect() {
        if (!SYS.isDetecting || !SYS.video.readyState === 4) return;
        
        // Predict objects
        SYS.predictions = await SYS.model.detect(SYS.video);
        
        // Loop
        requestAnimationFrame(AI.detect);
    }
};

// --- 2. MOCHI AVATAR ---
const Mochi = {
    x: SYS.width/2, y: SYS.height/2,
    targetX: SYS.width/2, targetY: SYS.height/2,
    r: 60,
    mood: 'NEUTRAL',
    
    update() {
        // Chase the most interesting object
        if (SYS.predictions.length > 0) {
            // Prioritize 'person', then others
            let target = SYS.predictions.find(p => p.class === 'person') || SYS.predictions[0];
            
            // Calculate center of bbox
            const centerX = target.bbox[0] + (target.bbox[2] / 2);
            const centerY = target.bbox[1] + (target.bbox[3] / 2);
            
            this.targetX = centerX;
            this.targetY = centerY;

            // React to object
            document.getElementById('target-name').innerText = target.class.toUpperCase();
            
            if (target.class === 'person') this.mood = 'HAPPY';
            else if (['cup', 'bottle', 'apple', 'banana'].includes(target.class)) this.mood = 'HUNGRY';
            else if (['cell phone', 'laptop', 'tv'].includes(target.class)) this.mood = 'TECH';
            else this.mood = 'CURIOUS';

        } else {
            // Center screen if nothing found
            this.targetX = SYS.width/2;
            this.targetY = SYS.height/2;
            this.mood = 'NEUTRAL';
            document.getElementById('target-name').innerText = "SCANNING...";
        }

        // Physics (Ease follow)
        this.x += (this.targetX - this.x) * 0.1;
        this.y += (this.targetY - this.y) * 0.1;
    },

    draw(ctx) {
        // Draw AR Boxes first
        SYS.predictions.forEach(p => {
            const [x, y, w, h] = p.bbox;
            
            // Cyber Box
            ctx.strokeStyle = 'rgba(0, 255, 204, 0.5)';
            ctx.lineWidth = 2;
            ctx.strokeRect(x, y, w, h);
            
            // Label
            ctx.fillStyle = 'rgba(0, 255, 204, 0.8)';
            ctx.fillRect(x, y - 25, w, 25);
            ctx.fillStyle = '#000';
            ctx.font = 'bold 14px Arial';
            ctx.fillText(`${p.class.toUpperCase()} ${Math.round(p.score*100)}%`, x + 5, y - 7);
        });

        // Draw Mochi
        ctx.shadowBlur = 20; ctx.shadowColor = 'rgba(255,255,255,0.5)';
        
        let color = '#ff9a9e'; // Pink
        if (this.mood === 'HUNGRY') color = '#ffcc00'; // Gold
        if (this.mood === 'TECH') color = '#00f3ff'; // Cyan
        if (this.mood === 'HAPPY') color = '#ff6b81'; // Dark Pink

        ctx.fillStyle = color;
        
        // Body
        ctx.save();
        ctx.translate(this.x, this.y);
        ctx.beginPath(); ctx.arc(0, 0, this.r, 0, Math.PI*2); ctx.fill();
        
        // Face
        this.drawFace(ctx);
        ctx.restore();
    },

    drawFace(ctx) {
        ctx.fillStyle = '#333';
        ctx.shadowBlur = 0;

        if (this.mood === 'TECH') {
            // Digital Eyes
            ctx.fillRect(-25, -10, 15, 15);
            ctx.fillRect(10, -10, 15, 15);
        } else {
            // Cute Eyes
            ctx.beginPath(); ctx.arc(-20, -10, 8, 0, Math.PI*2); ctx.fill();
            ctx.beginPath(); ctx.arc(20, -10, 8, 0, Math.PI*2); ctx.fill();
        }

        // Mouth
        ctx.strokeStyle = '#333'; ctx.lineWidth = 4; ctx.lineCap = 'round';
        ctx.beginPath();
        
        if (this.mood === 'HAPPY') {
            ctx.arc(0, 10, 10, 0, Math.PI); // Smile
        } else if (this.mood === 'HUNGRY') {
             ctx.arc(0, 15, 8, 0, Math.PI*2); // Open mouth
        } else {
            ctx.moveTo(-5, 15); ctx.lineTo(5, 15); // Neutral
        }
        ctx.stroke();
    }
};

// --- 3. SYSTEM ---
function loop() {
    SYS.ctx.clearRect(0, 0, SYS.width, SYS.height);
    Mochi.update();
    Mochi.draw(SYS.ctx);
    requestAnimationFrame(loop);
}

document.getElementById('btn-start').addEventListener('click', async () => {
    try {
        const stream = await navigator.mediaDevices.getUserMedia({ 
            video: { facingMode: 'environment' }, 
            audio: false 
        });
        SYS.video.srcObject = stream;
        
        // Wait for video to load
        SYS.video.onloadeddata = () => {
            document.getElementById('loader').style.display = 'none';
            SYS.isDetecting = true;
            
            SYS.canvas.width = window.innerWidth;
            SYS.canvas.height = window.innerHeight;
            SYS.ctx = SYS.canvas.getContext('2d');

            document.getElementById('ai-stat').innerText = "ACTIVE";
            document.getElementById('ai-stat').style.color = "#00ffcc";
            
            AI.detect(); // Start Tensor Loop
            loop(); // Start Visual Loop
            
            speak("Visual Cortex Online. I can see now!");
        };

    } catch(e) {
        alert("Camera access denied or not supported.");
    }
});

function speak(txt) {
    const u = new SpeechSynthesisUtterance(txt);
    u.pitch = 1.4; u.rate = 1.1;
    window.speechSynthesis.speak(u);
}

// Init
AI.init();

</script>
</body>
</html>
